# Ollama Configuration
OLLAMA_HOST=https://ollama.com
OLLAMA_API_KEY=your_api_key_here
OLLAMA_MODEL=gemma3-pro-preview

# Fallback Model (used when primary hits rate limits)
OLLAMA_FALLBACK_MODEL=kimi-k2-thinking:cloud

# For local Ollama only:
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3.2:latest

# App Configuration
APP_PORT=5001
MAX_UPLOAD_SIZE=100

# Image Generation (optional)
ENABLE_IMAGE_GENERATION=false

# Video Generation (optional)
ENABLE_VIDEO_GENERATION=false
